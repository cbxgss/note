# 1 引论

-   基础研究
    -   词法分析
        -   自动分词
        -   词性标注
        -   短语识别
    -   句法分析
    -   语义分析
    -   语用分析

## 基于规则的自然语言处理

理性主义

-   鲁棒性差
-   效 率低下

## 基于统计的自然语言处理

可以理解为通信的编码与解码， 原始语句就是一个已经编码的信息，然后根据统计的概率，解码出原始信息

-   从语料库中学习
-   n -gram 语言模型
    -   基于前n个词，预测当前词的概率
    -   一元语言模型: 认为每个词都是相互独立的
    -   二元语言模型: 当前词受到前一个词的影响
    -   三元语言模型

## 基于深度学习的自然语言处理

-   NLP方法
    -   理性主义(结构主义)
    -   感性主义
    -   经验主义(功能主义)
-   NLP研究存在的问题
    -   歧义: 注音歧义，分词歧义，短语歧义，句法歧义，语义歧义，语用歧义
    -   病构
    -   复述

# 2 数学基础

## 概率论基础

-   贝叶斯法则
-   概率分布
    -   二项分布
    -   正态分布
-   估计概率密度的方法
    -   最大似然估计
    -   最大后验估计

## 信息论基础

-   自信息量: $I(x_i)=-logp(x_i)$
-   信息熵: $H(X)=-\sum_{x\in X}p(x)log_2p(x)$​
-   联合熵: $H(X, Y)=-\sum_{x \in X}\sum_{y \in Y}p\{x, y\}log_2p\{x, y\}=H(X)+H(Y|X)$
-   条件熵: $H(X, Y)=\sum_{x \in X}p(x)H(Y|X=x)=-\sum_{x \in X}\sum_{y \in Y}p\{x, y\}log_2p\{y|x\}$​
-   互信息: $I(X, Y)=H(X)-H(X|Y)$

# 3 隐马尔科夫模型

## 马尔科夫模型

-   马尔科夫模型: 系统在$t$时刻处于状态$S_j$的概率，取决于其在1, 2, ..., t-1时的状态
-   一阶: 只和t-1有关

## 隐马尔科夫模型HMM

-   形式化描述: 一个HMM $\lambda = (S,O,A,B,\pi)$
    -   状态集合 $S = \{S_1, S_2, ..., S_N\}$，用 $q_t$ 表示在 $t$ 时的状态
    -   输出符号集合 $O = \{O_1, O_2,...,O_M\}$
    -   状态转移矩阵 $A=a_{ij}$  : 从 $S_i \rightarrow S_j$ 的概率
    -   可观察符号的概率分布矩阵 $B = b_j(k)$   : 在状态 $j$ 时输出符号 $v_k$ 的概率
    -   初始状态概率分布 $\pi = P(q_1=S_i)$
-   三个基本问题
    -   评估问题: 给定一个观察序列 $O=O_1O_2...O_T$ 和模型 $\lambda$，计算在 $P(O|\lambda)$
    -   解码问题: 给定一个观察序列 $O=O_1O_2...O_T$ 和模型 $\lambda$，如何计算状态序列 $Q=q_1...q_T$，使得 $Q$ 能最好地解释 $O$
    -   学习问题
-   应用
    -   自然语言处理: 
        -   词性标注

# 4 搭配

## 4.1 介绍

-   **搭配**: 由两个或两个以上的词所组成的语言表示
-   搭配的特征/标准
    -   通常非复合构词

## 4.2 发现搭配

-   **频率**

-   **均值和方差**

    -   一定距离的二元组
    -   均值: 平均偏移量
    -   方差: 低方差表示这两个词通常以一定的距离出现

-   **假设检验**: 判断高频率和低方差是否是偶然事件
    
    -   t检验: 正态分布
    -   $t = \frac{\mathop{x}\limits^- - \mu}{\sqrt{\frac{s^2}{N}}}$
        -   $s^2=p(1-p) \approx p$
    -   卡方检验: 非正态分布
    
-   **似然比**

-   **互信息**: 已知y的情况下，获得的有关x的信息量

    -   点互信息

        ![image-20211021001720328](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.assets/image-20211021001720328.png)

## 4.3 搭配的应用

# 5 语义消歧WSD

## 5.1 定义

-   语义歧义: 词语具有几个意思或语义
-   语义消歧

## 5.2 预备知识

-   有监督学习和无监督学习
    -   有监督学习
    -   无监督学习
    -   现实情况
-   伪词
-   算法性能的上下界

## 5.3 有监督消歧

-   基于贝叶斯分类的词义消歧义
-   基于互信息的WSD方法
-   基于词典的消歧
-   基于语义定义的消歧

## 5.4 基于词典的消歧

-   基于语义定义的WSD
-   基于词典释义的WSD
-   基于义类词典的消歧
-   在第二语言语料库翻译基础上的消歧
-   每篇文本一个语义，每个搭配一个语义

## 5.5 无监督消歧

-   分组上下判别-EM算法

# 6 词汇获取

## 6.1 介绍

-   总体目标: 设计算法和统计技术，通过对大规模文本语料库的挖掘，获取其中词语出现的各类形式，填补现有词典的不足
-   词汇获取问题
    -   搭配
    -   动词子范畴
    -   附着歧义
    -   选择倾向
    -   语义相似性

## 6.2 评价方法

|      |  对  | 不对 |
| :--: | :--: | :--: |
|  选  |  tp  |  fp  |
| 不选 |  fn  |  tn  |

-   精确率 $precision = \frac{tp}{tp+fp}$
-   召回率 $recall = \frac{tp}{tp+fn}$
-   F测量值 $F-measure = \frac{1}{\alpha \frac{1}{P}+(1-\alpha)\frac{1}{R}}$
-   漏识率 $Fallout = \frac{fp}{fp+tn}$

## 6.3 动词子范畴

-   子范畴
-   子范畴框架
-   学习子范畴框架的算法
    -   暗示
    -   假设检验

## 6.4 附着歧义

## 6.5 选择倾向

一个动词倾向于带什么宾语

-   选择倾向强度SPS: 动词约束直接宾语的强度

## 6.6 语义相似性

## 6.7 应用及进一步阅读

# 7. 概率上下文无关文法

## 7.1 背景知识

-   语言的非线性
-   CFG: 上下文无关文法

## 7.2 概率上下文无关文法 PCFG

-   PCFG: 给CFG每条规则一个概率值

## 7.3 PCFG的基本问题

-   句子概率计算 $P(w_{1m}|G)$
-   最佳句法分析树 $P(t|w_{1m},G)$
-   语法规则训练 $\mathop{argmax}\limits_G P(w_{1m}|G)$

## 7.4 PCFG的问题及解决方法

## 7.5 其他句法分析方法

-   依存语法 (本质上 等价于 词汇化的PCFG)

## 句法分析结果评估

-   基于任务的评价
-   基于目标的原则: 对答案
    -   严格: 0 or 1
    -   部分评价 [0, 1]

## PCFG的

-   PCFG的假设
    -   位置无关
    -   上下文无关
    -   祖先无关
-   PCFG独立性假设的弱化
    -   词汇化: 规则的成立概率随着具体的词变 ($V \rightarrow V_{take}$)
    -   结构化上下文的概率依存

# 8 文本分类

## 8.1 分类技术在自然语言中的应用

|     问题     |    对象    |   分类   |
| :----------: | :--------: | :------: |
|   词性标注   | 词的上下文 |   词性   |
|   词义消歧   | 词的上下文 |   词义   |
|   介词附着   |    句子    |  分析树  |
| 命名实体识别 |    句子    | 实体类别 |
|   作者识别   |    文档    |   作者   |
|   语言识别   |    文档    | 语言类型 |
|   文本分类   |    文档    |   主题   |

## 8.2 文本分类的一般过程

-   训练集
-   数学模型
-   训练过程
-   测试集
-   评价

## 8.3 朴素贝叶斯分类

-   假定: 对给定类，各个属性值的出现概率是互相独立的

    

## 8.4 K近邻

## 8.5 决策树分类和最大熵分类

## 8.6 SVM

# 9 文本聚类

## 9.1 聚类概述

-   目标
-   定义
-   用途
-   种类
    -   软聚类
    -   硬聚类: 可以兼类

## 9.2 层级聚类

-   单连通、全连通
-   平均连通
-   自顶向下聚类

## 9.3 非层级聚类

-   k-mean
-   EM算法

# 10 机器翻译

## 10.1 机器翻译概述

-   定义

## 10.2 基于规则的机器翻译

-   直接词汇翻译
-   基于句型转换
-   基于中间语言

## 10.3 基于实例的机器翻译

-   翻译记忆的直接翻译
-   基于实例的转换策略

## 10.4 基于统计的机器翻译

-   

## 10.5 机器翻译的评价

## 10.6 利用互联网获取双语语料

# 11 信息检索

## 11.1 概述

-   概念
    
    -   **信息检索**: 从**非结构化**的文档集中找出与用户需求相关的信息
    
    -   与其他技术的区别
    
        -   数据库: 是结构化的数据
        -   情报检索: 是介绍如何利用信息检索工具
    
    -   处理的对象

        -   非结构化数据
            -   文本数据: 新闻等
            -   网页: HTML、XML
            -   多媒体数据: 图像...
        -   目前最主要的处理对象是互联网
    
    -   典型的IR任务
    
        -   给定: 自然语言的文档集合 和 用户的Query
    
        -   查找: 和query相关的经过排序rank的文档子集
    
        -   IR系统
    
            ![image-20211014084645999](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.assets/image-20211014084645999.png)
    
    -   基于内容的图像查询: 根据图像的目标、颜色等查询
    
-   IR系统的体系结构
    
    -   系统要素
        -   文本处理形成索引词: 删除停用词，Stemming提取词干
        -   建索引: 为文档建立倒排索引表
        -   搜索: 用倒排索引检索和查询
        -   排序: 根据相关性
        -   用户界面
        -   查询操作
    -   Web搜索
        -   web通过spider生成文档语料库，作为文档集
    
-   历史
    
-   困难
    
    -   大量的数据
    -   很难获取非结构化文本的语义信息
    -   检索是在非受限域文档上进行的: 很难事先定义或分类
    -   不同的用户基础
    -   提问的意图、文档的意图的捕获困难
    -   网页是分布式的和互相连接的
    -   效率efficiency和效果effectiveness
    -   关键词搜索
        -   同义词
        -   多义词
    -   智能信息检索
    
-   相关领域
    
    -   数据库管理
    -   图书和情报科学
    -   人工智能
    -   自然语言处理
    -   机器学习
    
-   主要的搜索引擎
    
-   信息检索的应用
    
-   主要的研究机构、会议、期刊

## 11.2 评价

-   概述
    -   信息检索系统的目的: 在较小消耗的情况下尽快、全面返回准确结果
    -   IR中评价
        -   效率efficiency: 开销
        -   效果 effectiveness: 返回量、排序
        -   其他指标
-   基本指标
    -   P precision: 返回的都对
    -   R recall: 对的都返回
    -   F-measure: $F_1 = \frac{2PR}{P+R}$
-   **TREC评测**
    -   TREC的查询形式
    -   **Pooling技术**: n个系统的检索结果，放在一个pool中，专家判断哪些与query相关，在pool之外的文档自动认为不相关
    -   **MAP指标**: 可以比较“序”
        -   $MAP=\frac{1}{N}\sum\limits_{j=1}^N \frac{1}{Q} \sum\limits_{i=1}^{Q_j}P(doc_i)$
        -   $Q_j$: 查询 $j$ 的相关文档数
        -   $N$: 查询数
        -   $P(doc_i)$: 第 $i$ 个相关文档的 $precision$
    -   **11-point AP**: $P_{11-pt}=\frac{1}{11}\sum\limits_{j=0}^{10} \frac{1}{N}P_i(r_j)$
        -   $r_j = \frac{j}{10}$: 11个标准的 $recall$ 点
        -   当有的点不知道时，插值: 对于 $P_i(r_j)$:
            -   如果 $P_i(R=r)$ 存在，则 $max(r_j \le r \le r_{j+1}) P_i(R=r)$
            -   其他: $P_i(r_{j+1})$
        -   比较PR曲线的面积
-   其他评价指标
    -   **Break Point**: R=P的点

## 11.3 信息检索模型

-   概述
    -   四元组 $[D, Q, F, R(q_i, d_j)]$
        -   D: 文档集合
        -   Q: 查询集合
        -   F: 框架
        -   $R(q_i, d_i)$: 相似度排序函数
    -   核心问题
        -   用户的需求表示
        -   文档的表示
        -   相似匹配与排序
        -   反馈
    -   模型分类
    -   两种主要方式
        -   特别检索: D不变，Q在变
        -   过滤: Q不变，D在变
-   **布尔模型**(集合论)
    -   查询是用 $and, or, not$ 连接组成的布尔表达式
-   **向量空间模型 VSM**(代数)
    -   索引项 / 词表: 类似分类
        -   假设: 索引项是不相关的，正交的，形成一个向量空间
    -   查询: n个索引项的则可以表示为有n个元素的线性组合
    -   相似度计算
        -   内积
        -   余弦相似度度量: 计算两个向量的夹角
    -   文档和词项的权重
-   **概率模型**(人工智能)
    -   基本思想
        -   用户给了一个查询，就有一个只有与查询完全相关文档构成的理想结果集合，记为 $R
        -   如果知道 $R$ 的特征，就可以找到所有相关文档
        -   查询就是寻找 $R$ 特征的过程
    -   每次查询完后，由用户判断，然后继续估计 $R$ 的特征
    -   相关概念
        -   贝叶斯定理: $P(A|B)=\frac{P(B|A)P(A)}{P(B)}$
        -   若索引词互相独立，则 $P(d)=P(x_1)...P(x_n)$
            -   $d$ 是文档
    -   **二元独立检索模型 BIR**
        -   含义
            -   索引项的权重都是二值的
            -   索引项之间相互独立
        -   文档和查询都可以用二元向量 $w_{ij}$ 表示
            -   文档 $d$: $w_{ij}=1$ 表示可以用索引项 $i$ 来表示
            -   查询 $q$: $w_{iq}=1$ 表示查询可以用索引项 $i$ 描述
-   **潜在语义索引模型**(概率统计)
    -   **潜在语义索引 LSI**
    -   思想
        -   把每个文档视为，以词汇为维度的空间中的一个点，认为一个包含语义的文档的分布不是随机的，服从某种语义分布
        -   把每个词汇也视为，以文档为维度的空间里的一个点

## 11.4 网络蜘蛛

### 11.4.1 概述

### 11.4.2 Spider基本工作原理

-   基本工作流程
    -   初始化采集URL种子队列
    -   重复以下
        -   从队列中取出URL
        -   下载并分析网页
        -   从网页抽取更多URL，放入队列
-   简单Spider的问题
    -   规模问题: 必须要分布式处理
    -   重复网页
    -   作弊网页和采集器陷阱
    -   礼貌性问题: 对网站访问要遵循协议规定，间隔要合适
    -   新鲜度问题: 定期更新

### 11.4.3 关键问题和技术

-   抓取策略
    -   遍历
    -   设置访问的层数
-   分布式采集
-   内容重复判别
-   作弊页面、采集器陷阱处理
    -   一些恶意服务器可以产生无穷的链接网页序列
-   礼貌性、新鲜度
    -   礼貌性: 不要太频繁
    -   新鲜度: 对某些网站频率要高

### 11.4.4 网站运营者对其态度

## 11.5 相关反馈和查询扩展

### 11.5.1 问题背景

-   原因
    -   用户不知道怎么构建好的查询
    -   用户有时不知道查询什么，需要看了结果后细化
-   **提高召回率的方法**
    -   局部方法: **相关反馈**
    -   全局方法: **查询扩展**

### 11.5.2 相关反馈

-   思想
    -   用户提交一个查询，搜索引擎返回一系列文档
    -   用户标记相关和不相关
    -   搜索引擎根据标记计算得到信息需求的一个新查询表示
    -   对新查询进行处理，返回新结果
-   反馈分类
    -   **显式相关反馈**
    -   **隐式相关反馈**: 通过跟踪用户行为
    -   **伪相关反馈或盲相关反馈**: 系统之间假设返回文档的前k篇是相关的，然后进行反馈
-   可以循环几次
-   不仅仅局限与文档，图片也可以
-   核心概念: **质心**
    -   文档是高维空间中的点
    -   可以计算多个文档的质心: $D$ 是文档集合
-   **Rocchio算法**
    -   $\mathop{q}_{opt}\limits^\rightarrow$: 与相关文档和不相关文档的分布内积只差最大的向量
    -   修改相关文档的质心来查询
    -   正反馈和负反馈
-   存在的问题
    -   开销大: 新查询往往很长
    -   用户不愿意提供显式的相关反馈
        -   隐式: 鼠标键盘动作，用户眼球动作
-   新查询词的选择
    -   基于**局部聚类**的方法
    -   基于**局部上下文分析LCA**的方法

### 11.5.3 查询扩展

主要使用的信息: 同义词或近义词

-   基于人工词典
-   基于自动构建词典
    -   两个词的上下文共现词类似
    -   两个词同一些相同的词由某种给定语法关系
-   基于查询日志
    -   用户查了A后，经常查B
    -   用户查了A后，经常点B的URL

## 11.6 Web页面的评分机制

### 11.6.1 Web中的链接

-   **反向链接 Backlink**
    -   定义: 从其他页面指向当前页面的链接
    -   反向链接数
    -   反向链接重要性: 反向链接来自的网页的重要性
    -   反向链接分配: 指向当前页面的页面，其反向链接的分配情况

### 11.6.2 PageRank

-   **随机冲浪模型**

    -   前提假设: 不返回已经浏览过的页面
    -   模型: 给定一个随机页面，按页面提供的链接向前浏览的概率是 $q$，随机跳到其他页面的概率是 $1-q$
    -   $PageRank$值: 浏览每个页面的概率分配

-   公式1: $R(u) = (1-q)+q \sum\limits_{v \in B_u} \frac{R(v)}{N_v}$

    -   $u$: 一个Web页面
    -   $B_v$: 指向 $u$ 的页面集合
    -   $N_v$: $v$ 所包含的指向外部链接数

-   **矩阵求解**

    -   $A_{ij}$: 第 $j$ 个页面指向第 $i$ 个页面的概率

    -   $r$ 是 $A$ 的特征向量，则页面获得的对应概率可以通过下面迭代:
        -   $r = qAr$
    -   不按链接浏览，从其他页面随机跳过来的概率部分，这样迭代
        -   $r=\frac{1-q}{N}Ir$
            -   $N$: 所有页面数
            -   $I$: 各个元素均为1的矩阵
    -   综合上面得到新迭代公式
        -   $r = Br$
        -   $B=qA+\frac{1-q}{N}I$
    -   矩阵算法
        -   初始化
        -   迭代

-   锚文本比文档里的文本更重要

### 11.6.3 HITS

-   hub权重 $h$
    -   hubs: 推荐页面，带有指向高质量页面的链接
-   authority权重 $a$
    -   authorities: 由其他页面标识的页面，特别是hubs

-   HITS算法

## 11.7 文本的处理

抽取什么词作为索引词 index term，如何索引

### 11.7.1 词法分析

-   将文档的字符串序列，变成词序列
-   英文
-   中文

### 11.7.2 停用词消除

-   停用词: 在大部分文档出现，而对检索没有意义的词
-   消除方法
    -   查表法: 事先规定哪些是
    -   基于DF的方法: 统计每个词的DF，超过阈值就去掉

### 11.7.3 词干还原

-   英文: 还原为词根

### 11.7.4 Term选择

-   方法一: 选择名词
-   方法二: 选择短语
-   方法三: 名词\[\]\[\]，其中每个名词\[\]里的名词意思接近

## 11.8 文本索引

### 11.8.1 字符串索引

-   字符串匹配
    -   暴力
    -   KMP

### 11.8.2 前向索引

![image-20211020201300641](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.assets/image-20211020201300641.png)

### 11.8.3 倒排索引

![image-20211020201412011](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.assets/image-20211020201412011.png)

## 11.9 多媒体检索

